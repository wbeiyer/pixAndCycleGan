----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ../datasets/thread1           	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 256                           
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: cycle_gan                     
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: thread1_cyclegan              	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: True                          
                  no_flip: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 4250
initialize network with normal
initialize network with normal
initialize network with normal
initialize network with normal
model [CycleGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 11.378 M
[Network G_B] Total number of parameters : 11.378 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 5 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 6 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 7 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 8 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 9 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 10, iters 42500
D_A: 0.19527115493969005
G_A: 0.4395987846851349
cycle_A: 0.8604599448378362
idt_A: 0.39404892624991344
D_B: 0.20277000496865194
G_B: 0.488138085903819
cycle_B: 0.9298348008981523
idt_B: 0.36629906437374815
End of epoch 10 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 11 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 12 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 13 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 14 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 15 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 16 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 17 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 18 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 19 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 20, iters 85000
D_A: 0.16110203508024706
G_A: 0.49524492086207167
cycle_A: 0.6464964337967993
idt_A: 0.33219227894839337
D_B: 0.19134720601272934
G_B: 0.4998141215071082
cycle_B: 0.7821003577980925
idt_B: 0.292878458473174
End of epoch 20 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 21 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 22 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 23 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 24 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 25 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 26 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 27 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 28 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 29 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 30, iters 127500
D_A: 0.13846641505509616
G_A: 0.5533989080720965
cycle_A: 0.558623348073034
idt_A: 0.29948088833163766
D_B: 0.1808324382739032
G_B: 0.5195664848145097
cycle_B: 0.730698555347674
idt_B: 0.25441226767098724
End of epoch 30 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 31 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 32 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 33 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 34 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 35 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 36 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 37 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 38 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 39 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 40, iters 170000
D_A: 0.1257536265609019
G_A: 0.5928990979069735
cycle_A: 0.4965644745875479
idt_A: 0.28187774799860027
D_B: 0.17361983310321674
G_B: 0.5318204005020944
cycle_B: 0.6999017129759578
idt_B: 0.22824488970855086
End of epoch 40 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 41 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 42 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 43 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 44 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 45 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 46 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 47 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 48 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 49 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 50, iters 212500
D_A: 0.110017237980357
G_A: 0.6417467717826366
cycle_A: 0.45882379740788876
idt_A: 0.2715936041378197
D_B: 0.1671042580867515
G_B: 0.5546680779223714
cycle_B: 0.6859757839127937
idt_B: 0.21426329162916827
End of epoch 50 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 51 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 52 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 53 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 54 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 55 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 56 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 57 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 58 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 59 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 60, iters 255000
D_A: 0.10397107329175753
G_A: 0.6590744606221424
cycle_A: 0.4214851974453777
idt_A: 0.26272905417000325
D_B: 0.16063702461057727
G_B: 0.5626142178931657
cycle_B: 0.6691615971551441
idt_B: 0.19259716842368738
End of epoch 60 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 61 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 62 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 63 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 64 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 65 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 66 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 67 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 68 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 69 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 70, iters 297500
D_A: 0.10089598423768492
G_A: 0.6705073073144783
cycle_A: 0.4063138191007653
idt_A: 0.26351574373420544
D_B: 0.1561726724849466
G_B: 0.5837761060790543
cycle_B: 0.682915017110679
idt_B: 0.1863851318770458
End of epoch 70 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 71 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 72 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 73 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 74 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 75 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 76 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 77 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 78 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 79 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 80, iters 340000
D_A: 0.0988765087603208
G_A: 0.6795976595955299
cycle_A: 0.38266709862239934
idt_A: 0.24911673937228454
D_B: 0.154122370152789
G_B: 0.5877267675160923
cycle_B: 0.6639529917643351
idt_B: 0.18122237227333587
End of epoch 80 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 81 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 82 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 83 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 84 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 85 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 86 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 87 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 88 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 89 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 90, iters 382500
D_A: 0.09755905826543183
G_A: 0.6896400453180951
cycle_A: 0.3608850153363721
idt_A: 0.24371303122994653
D_B: 0.15878606384247543
G_B: 0.5713080464121612
cycle_B: 0.6541005326281576
idt_B: 0.16182908233010676
End of epoch 90 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 91 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 92 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 93 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 94 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 95 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 96 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 97 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 98 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 99 / 200 	
learning rate 0.0002000 -> 0.0001980
saving the model at the end of epoch 100, iters 425000
D_A: 0.09398100557638442
G_A: 0.7014487376199926
cycle_A: 0.3564335596998743
idt_A: 0.23465340868303525
D_B: 0.1507555610285524
G_B: 0.5962541540547767
cycle_B: 0.6392561639801544
idt_B: 0.16119148321335053
End of epoch 100 / 200 	
learning rate 0.0001980 -> 0.0001960
End of epoch 101 / 200 	
learning rate 0.0001960 -> 0.0001941
End of epoch 102 / 200 	
learning rate 0.0001941 -> 0.0001921
End of epoch 103 / 200 	
learning rate 0.0001921 -> 0.0001901
End of epoch 104 / 200 	
learning rate 0.0001901 -> 0.0001881
End of epoch 105 / 200 	
learning rate 0.0001881 -> 0.0001861
End of epoch 106 / 200 	
learning rate 0.0001861 -> 0.0001842
End of epoch 107 / 200 	
learning rate 0.0001842 -> 0.0001822
End of epoch 108 / 200 	
learning rate 0.0001822 -> 0.0001802
End of epoch 109 / 200 	
learning rate 0.0001802 -> 0.0001782
saving the model at the end of epoch 110, iters 467500
D_A: 0.0904408239161267
G_A: 0.7158210867669652
cycle_A: 0.31877960787597115
idt_A: 0.23221158962228391
D_B: 0.1453722333244103
G_B: 0.6043467829972505
cycle_B: 0.633032062051763
idt_B: 0.14521291988384089
End of epoch 110 / 200 	
learning rate 0.0001782 -> 0.0001762
End of epoch 111 / 200 	
learning rate 0.0001762 -> 0.0001743
End of epoch 112 / 200 	
learning rate 0.0001743 -> 0.0001723
End of epoch 113 / 200 	
learning rate 0.0001723 -> 0.0001703
End of epoch 114 / 200 	
learning rate 0.0001703 -> 0.0001683
End of epoch 115 / 200 	
learning rate 0.0001683 -> 0.0001663
End of epoch 116 / 200 	
learning rate 0.0001663 -> 0.0001644
End of epoch 117 / 200 	
learning rate 0.0001644 -> 0.0001624
End of epoch 118 / 200 	
learning rate 0.0001624 -> 0.0001604
End of epoch 119 / 200 	
learning rate 0.0001604 -> 0.0001584
saving the model at the end of epoch 120, iters 510000
D_A: 0.08822599407329279
G_A: 0.7242708151656039
cycle_A: 0.2843425146191764
idt_A: 0.2306977863965782
D_B: 0.14392045088167138
G_B: 0.6087324852141387
cycle_B: 0.6319996668211157
idt_B: 0.1318001030035983
End of epoch 120 / 200 	
learning rate 0.0001584 -> 0.0001564
End of epoch 121 / 200 	
learning rate 0.0001564 -> 0.0001545
End of epoch 122 / 200 	
learning rate 0.0001545 -> 0.0001525
End of epoch 123 / 200 	
learning rate 0.0001525 -> 0.0001505
End of epoch 124 / 200 	
learning rate 0.0001505 -> 0.0001485
End of epoch 125 / 200 	
learning rate 0.0001485 -> 0.0001465
End of epoch 126 / 200 	
learning rate 0.0001465 -> 0.0001446
End of epoch 127 / 200 	
learning rate 0.0001446 -> 0.0001426
End of epoch 128 / 200 	
learning rate 0.0001426 -> 0.0001406
End of epoch 129 / 200 	
learning rate 0.0001406 -> 0.0001386
saving the model at the end of epoch 130, iters 552500
D_A: 0.0853288419584141
G_A: 0.7347507783257786
cycle_A: 0.26841956377788173
idt_A: 0.2195074156301014
D_B: 0.12961838979843784
G_B: 0.6444418839864872
cycle_B: 0.6206670238248018
idt_B: 0.12897573946511565
End of epoch 130 / 200 	
learning rate 0.0001386 -> 0.0001366
End of epoch 131 / 200 	
learning rate 0.0001366 -> 0.0001347
End of epoch 132 / 200 	
learning rate 0.0001347 -> 0.0001327
End of epoch 133 / 200 	
learning rate 0.0001327 -> 0.0001307
End of epoch 134 / 200 	
learning rate 0.0001307 -> 0.0001287
End of epoch 135 / 200 	
learning rate 0.0001287 -> 0.0001267
End of epoch 136 / 200 	
learning rate 0.0001267 -> 0.0001248
End of epoch 137 / 200 	
learning rate 0.0001248 -> 0.0001228
End of epoch 138 / 200 	
learning rate 0.0001228 -> 0.0001208
End of epoch 139 / 200 	
learning rate 0.0001208 -> 0.0001188
saving the model at the end of epoch 140, iters 595000
D_A: 0.08625998240139554
G_A: 0.7358205746245735
cycle_A: 0.24818289526607432
idt_A: 0.21961007785418254
D_B: 0.12836814961089368
G_B: 0.6435287465525462
cycle_B: 0.6183227982009926
idt_B: 0.11438985557102611
End of epoch 140 / 200 	
learning rate 0.0001188 -> 0.0001168
End of epoch 141 / 200 	
learning rate 0.0001168 -> 0.0001149
End of epoch 142 / 200 	
learning rate 0.0001149 -> 0.0001129
End of epoch 143 / 200 	
learning rate 0.0001129 -> 0.0001109
End of epoch 144 / 200 	
learning rate 0.0001109 -> 0.0001089
End of epoch 145 / 200 	
learning rate 0.0001089 -> 0.0001069
End of epoch 146 / 200 	
learning rate 0.0001069 -> 0.0001050
End of epoch 147 / 200 	
learning rate 0.0001050 -> 0.0001030
End of epoch 148 / 200 	
learning rate 0.0001030 -> 0.0001010
End of epoch 149 / 200 	
learning rate 0.0001010 -> 0.0000990
saving the model at the end of epoch 150, iters 637500
D_A: 0.08537543013275546
G_A: 0.737363187350771
cycle_A: 0.22971243817296208
idt_A: 0.2163798842572518
D_B: 0.12500481368382188
G_B: 0.6459052398483105
cycle_B: 0.6169894688741496
idt_B: 0.10551059394382943
End of epoch 150 / 200 	
learning rate 0.0000990 -> 0.0000970
End of epoch 151 / 200 	
learning rate 0.0000970 -> 0.0000950
End of epoch 152 / 200 	
learning rate 0.0000950 -> 0.0000931
End of epoch 153 / 200 	
learning rate 0.0000931 -> 0.0000911
End of epoch 154 / 200 	
learning rate 0.0000911 -> 0.0000891
End of epoch 155 / 200 	
learning rate 0.0000891 -> 0.0000871
End of epoch 156 / 200 	
learning rate 0.0000871 -> 0.0000851
End of epoch 157 / 200 	
learning rate 0.0000851 -> 0.0000832
End of epoch 158 / 200 	
learning rate 0.0000832 -> 0.0000812
End of epoch 159 / 200 	
learning rate 0.0000812 -> 0.0000792
saving the model at the end of epoch 160, iters 680000
D_A: 0.09226559519702021
G_A: 0.7185762587049428
cycle_A: 0.21157799912391997
idt_A: 0.21090976906962938
D_B: 0.11978034557577441
G_B: 0.6506227493652088
cycle_B: 0.6078242537800825
idt_B: 0.09890158265552129
End of epoch 160 / 200 	
learning rate 0.0000792 -> 0.0000772
End of epoch 161 / 200 	
learning rate 0.0000772 -> 0.0000752
End of epoch 162 / 200 	
learning rate 0.0000752 -> 0.0000733
End of epoch 163 / 200 	
learning rate 0.0000733 -> 0.0000713
End of epoch 164 / 200 	
learning rate 0.0000713 -> 0.0000693
End of epoch 165 / 200 	
learning rate 0.0000693 -> 0.0000673
End of epoch 166 / 200 	
learning rate 0.0000673 -> 0.0000653
End of epoch 167 / 200 	
learning rate 0.0000653 -> 0.0000634
End of epoch 168 / 200 	
learning rate 0.0000634 -> 0.0000614
End of epoch 169 / 200 	
learning rate 0.0000614 -> 0.0000594
saving the model at the end of epoch 170, iters 722500
D_A: 0.09834473612816895
G_A: 0.6942085069610792
cycle_A: 0.20055780482527746
idt_A: 0.20980673482608708
D_B: 0.1142283122828778
G_B: 0.66177925821832
cycle_B: 0.6143965769157307
idt_B: 0.09484582704663455
End of epoch 170 / 200 	
learning rate 0.0000594 -> 0.0000574
End of epoch 171 / 200 	
learning rate 0.0000574 -> 0.0000554
End of epoch 172 / 200 	
learning rate 0.0000554 -> 0.0000535
End of epoch 173 / 200 	
learning rate 0.0000535 -> 0.0000515
End of epoch 174 / 200 	
learning rate 0.0000515 -> 0.0000495
End of epoch 175 / 200 	
learning rate 0.0000495 -> 0.0000475
End of epoch 176 / 200 	
learning rate 0.0000475 -> 0.0000455
End of epoch 177 / 200 	
learning rate 0.0000455 -> 0.0000436
End of epoch 178 / 200 	
learning rate 0.0000436 -> 0.0000416
End of epoch 179 / 200 	
learning rate 0.0000416 -> 0.0000396
saving the model at the end of epoch 180, iters 765000
D_A: 0.10506852053018177
G_A: 0.6691431745956926
cycle_A: 0.1922939814803848
idt_A: 0.20761630094741293
D_B: 0.10454488323212546
G_B: 0.6795050397366286
cycle_B: 0.6134945429955363
idt_B: 0.08783076189512555
End of epoch 180 / 200 	
learning rate 0.0000396 -> 0.0000376
End of epoch 181 / 200 	
learning rate 0.0000376 -> 0.0000356
End of epoch 182 / 200 	
learning rate 0.0000356 -> 0.0000337
End of epoch 183 / 200 	
learning rate 0.0000337 -> 0.0000317
End of epoch 184 / 200 	
learning rate 0.0000317 -> 0.0000297
End of epoch 185 / 200 	
learning rate 0.0000297 -> 0.0000277
End of epoch 186 / 200 	
learning rate 0.0000277 -> 0.0000257
End of epoch 187 / 200 	
learning rate 0.0000257 -> 0.0000238
End of epoch 188 / 200 	
learning rate 0.0000238 -> 0.0000218
End of epoch 189 / 200 	
learning rate 0.0000218 -> 0.0000198
saving the model at the end of epoch 190, iters 807500
D_A: 0.10973973915506811
G_A: 0.6483500951809041
cycle_A: 0.18392676428138444
idt_A: 0.20659080164166688
D_B: 0.09498494251707898
G_B: 0.6950012872052543
cycle_B: 0.6188555415591828
idt_B: 0.0849614060886961
End of epoch 190 / 200 	
learning rate 0.0000198 -> 0.0000178
End of epoch 191 / 200 	
