----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ./datasets/thread             	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 256                           
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: cycle_gan                     
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: thread_cyclegan               	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: True                          
                  no_flip: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 16224
initialize network with normal
initialize network with normal
initialize network with normal
initialize network with normal
model [CycleGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 11.378 M
[Network G_B] Total number of parameters : 11.378 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 5 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 6 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 7 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 8 / 200 	
learning rate 0.0002000 -> 0.0002000
End of epoch 9 / 200 	
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 10, iters 162240
D_A: 0.11553169233543997
G_A: 0.5670563280937184
cycle_A: 0.29896757065139884
idt_A: 0.3383058963742574
D_B: 0.10270882484191272
G_B: 0.719798893382517
cycle_B: 1.0221591645675385
idt_B: 0.13459187667240885
End of epoch 10 / 200 	
